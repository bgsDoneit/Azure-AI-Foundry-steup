{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bgsDoneit/Azure-AI-Foundry-steup/blob/master/gcp_rag_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Retrieval Augmented Generation (RAG) improves Large Language Models (LLMs) by allowing them to access and process external information sources during generation. This ensures the model's responses are grounded in factual data and avoids hallucinations.\n",
        "\n",
        "A common problem with LLMs is that they don't understand private knowledge, that\n",
        "is, your organization's data. With RAG Engine, you can enrich the\n",
        "LLM context with additional private information, because the model can reduce\n",
        "hallucinations and answer questions more accurately.\n",
        "\n",
        "By combining additional knowledge sources with the existing knowledge that LLMs\n",
        "have, a better context is provided. The improved context along with the query\n",
        "enhances the quality of the LLM's response.\n",
        "\n",
        "The following concepts are key to understanding Vertex AI RAG Engine. These concepts are listed in the order of the\n",
        "retrieval-augmented generation (RAG) process.\n",
        "\n",
        "1. **Data ingestion**: Intake data from different data sources. For example,\n",
        "  local files, Google Cloud Storage, and Google Drive.\n",
        "\n",
        "1. **Data transformation**: Conversion of the data in preparation for indexing. For example, data is split into chunks.\n",
        "\n",
        "1. **Embedding**: Numerical representations of words or pieces of text. These numbers capture the\n",
        "   semantic meaning and context of the text. Similar or related words or text\n",
        "   tend to have similar embeddings, which means they are closer together in the\n",
        "   high-dimensional vector space.\n",
        "\n",
        "1. **Data indexing**: RAG Engine creates an index called a corpus.\n",
        "   The index structures the knowledge base so it's optimized for searching. For\n",
        "   example, the index is like a detailed table of contents for a massive\n",
        "   reference book.\n",
        "\n",
        "1. **Retrieval**: When a user asks a question or provides a prompt, the retrieval\n",
        "  component in RAG Engine searches through its knowledge\n",
        "  base to find information that is relevant to the query.\n",
        "\n",
        "1. **Generation**: The retrieved information becomes the context added to the\n",
        "  original user query as a guide for the generative AI model to generate\n",
        "  factually grounded and relevant responses.\n",
        "\n",
        "For more information, refer to the public documentation for [Vertex AI RAG Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and Google Gen AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "outputId": "fdeadb41-afff-4c33-d34e-ce8e68291c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XRvKdaPDTznN",
        "outputId": "04cbd6f3-5585-4437-da02-c290e578146c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "from google import genai\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"mygcpaiagentlanggraphtavliy\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"europe-west3\")\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore\n",
        "from vertexai import rag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Create a RAG Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "# Currently supports Google first-party embedding models\n",
        "EMBEDDING_MODEL = \"publishers/google/models/text-embedding-005\"  # @param {type:\"string\", isTemplate: true}\n",
        "\n",
        "rag_corpus = rag.create_corpus(\n",
        "    display_name=\"my-rag-corpus1\",\n",
        "    backend_config=rag.RagVectorDbConfig(\n",
        "        rag_embedding_model_config=rag.RagEmbeddingModelConfig(\n",
        "            vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
        "                publisher_model=EMBEDDING_MODEL\n",
        "            )\n",
        "        )\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197c585b61b2"
      },
      "source": [
        "### Check the corpus just created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f229b13dc617",
        "outputId": "dcdbebce-23cc-4265-93a0-b84388ebd994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ListRagCorporaPager<rag_corpora {\n",
              "  name: \"projects/mygcpaiagentlanggraphtavliy/locations/europe-west3/ragCorpora/2305843009213693952\"\n",
              "  display_name: \"my-rag-corpus\"\n",
              "  create_time {\n",
              "    seconds: 1765987969\n",
              "    nanos: 354544000\n",
              "  }\n",
              "  update_time {\n",
              "    seconds: 1765987969\n",
              "    nanos: 354544000\n",
              "  }\n",
              "  corpus_status {\n",
              "    state: ACTIVE\n",
              "  }\n",
              "  vector_db_config {\n",
              "    rag_managed_db {\n",
              "      knn {\n",
              "      }\n",
              "    }\n",
              "    rag_embedding_model_config {\n",
              "      vertex_prediction_endpoint {\n",
              "        endpoint: \"projects/mygcpaiagentlanggraphtavliy/locations/europe-west3/publishers/google/models/text-embedding-005\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "rag_corpora {\n",
              "  name: \"projects/mygcpaiagentlanggraphtavliy/locations/europe-west3/ragCorpora/6917529027641081856\"\n",
              "  display_name: \"my-rag-corpus1\"\n",
              "  create_time {\n",
              "    seconds: 1765988285\n",
              "    nanos: 8692000\n",
              "  }\n",
              "  update_time {\n",
              "    seconds: 1765988285\n",
              "    nanos: 8692000\n",
              "  }\n",
              "  corpus_status {\n",
              "    state: ACTIVE\n",
              "  }\n",
              "  vector_db_config {\n",
              "    rag_managed_db {\n",
              "      knn {\n",
              "      }\n",
              "    }\n",
              "    rag_embedding_model_config {\n",
              "      vertex_prediction_endpoint {\n",
              "        endpoint: \"projects/mygcpaiagentlanggraphtavliy/locations/europe-west3/publishers/google/models/text-embedding-005\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              ">"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "rag.list_corpora()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c52924cc1440"
      },
      "source": [
        "### Upload a local file to the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4976ffe8564f",
        "outputId": "9f5e748c-0e8a-4014-b83d-752bdfd85253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.md\n",
        "\n",
        "\n",
        "Apollo Clinic\n",
        "#1, Near Mc.Donalds, Prakasam Salai, Valasaravakkam, Chennai, Tamil Nadu, India - 600087\n",
        "Phone No: 1860 500 7788\n",
        "Email: kothandaram.rj@apolloclinic.com\n",
        "\n",
        "Patient Name: RAMANI BHASKARAN\n",
        "Age/Gender: 58Y/Female\n",
        "Physician: Dr. Madhavi\n",
        "\n",
        "Purpose of Visit: Routine Health Check\n",
        "\n",
        "PHYSICAL EXAMINATION:\n",
        "- Weight: 69 Kg\n",
        "- Height: 157 cm\n",
        "- BMI: 27.99\n",
        "- Pulse: 85 BPM\n",
        "- SpO2: 98%\n",
        "- Temperature: 97°F\n",
        "- BP: 150/80 mmHg\n",
        "- Respiratory Rate: 16/min\n",
        "\n",
        "OBSERVATIONS:\n",
        "- Pallor: No\n",
        "- Icterus: No\n",
        "- Cyanosis: No\n",
        "- Clubbing: No\n",
        "- Koilonychia: No\n",
        "- Edema: No\n",
        "\n",
        "IMPRESSIONS:\n",
        "- Pre Diabetic Stage\n",
        "- Hypertension\n",
        "- Vitamin D Deficiency\n",
        "- Vitamin B12 Deficiency\n",
        "- Cervical Spondylosis\n",
        "- Bilateral Carotid Plaques\n",
        "\n",
        "LAB RESULTS SUMMARY:\n",
        "\n",
        "Blood:\n",
        "- PCV: 35.90% (Low)\n",
        "- HbA1c: 6.2%\n",
        "- eAG: 131 mg/dL\n",
        "- Hemoglobin: 12 g/dL\n",
        "- RBC Count: 4.07 M/cu.mm\n",
        "- TLC: 7,900\n",
        "- Platelet Count: 249,000\n",
        "\n",
        "Lipid Profile:\n",
        "- Total Cholesterol: 170 mg/dL\n",
        "- Triglycerides: 199 mg/dL (High)\n",
        "- HDL: 43 mg/dL\n",
        "- LDL: 87.2 mg/dL\n",
        "- VLDL: 39.8 mg/dL (High)\n",
        "\n",
        "Renal Function:\n",
        "- Creatinine: 0.74 mg/dL\n",
        "- Urea: 16.00 mg/dL (Low)\n",
        "- BUN: 7.5 mg/dL (Low)\n",
        "\n",
        "Liver Function:\n",
        "- Bilirubin Total: 0.47 mg/dL\n",
        "- ALT/SGPT: 15 U/L\n",
        "- AST/SGOT: 15 U/L\n",
        "- Albumin: 4.5 g/dL\n",
        "\n",
        "Thyroid Profile:\n",
        "- T3: 0.83 ng/mL\n",
        "- T4: 7.43 µg/dL\n",
        "- TSH: 3.931 µIU/mL\n",
        "\n",
        "Vitamin Levels:\n",
        "- Vitamin B12: 50 pg/mL (Low)\n",
        "- Vitamin D (25-OH): 15.4 ng/mL (Low)\n",
        "\n",
        "Urine Examination:\n",
        "- pH: 5.5\n",
        "- Specific Gravity: 1.025\n",
        "- All parameters: Normal\n",
        "\n",
        "Other Tests:\n",
        "- Rheumatoid Factor: Negative\n",
        "- CA-125: 6.3 U/mL\n",
        "\n",
        "AI RISK SCORES:\n",
        "- Risk of Heart Disease: 4 (Low Risk)\n",
        "- Prediabetes: 2.5/100 (Low Risk)\n",
        "- COPD Risk Assessment: 27% (Low Risk)\n",
        "\n",
        "Note: Radiology reports are available separately.\n",
        "\n",
        "DISCLAIMER: All lab results are subject to clinical interpretation by qualified medical professionals and not to be used for medicolegal purposes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "529390917c29"
      },
      "outputs": [],
      "source": [
        "rag_file = rag.upload_file(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    path=\"test.md\",\n",
        "    display_name=\"test.md\",\n",
        "    description=\"my test file\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5269a0c2786d"
      },
      "source": [
        "### Import files from Google Cloud Storage\n",
        "\n",
        "Remember to grant \"Viewer\" access to the \"Vertex RAG Data Service Agent\" (with the format of `service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com`) for your Google Cloud Storage bucket.\n",
        "\n",
        "For this example, we'll use a public GCS bucket containing earning reports from Alphabet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5910ae450f69"
      },
      "outputs": [],
      "source": [
        "# INPUT_GCS_BUCKET = (\n",
        "#     \"gs://cloud-samples-data/gen-app-builder/search/alphabet-investor-pdfs/\"\n",
        "# )\n",
        "\n",
        "# response = rag.import_files(\n",
        "#     corpus_name=rag_corpus.name,\n",
        "#     paths=[INPUT_GCS_BUCKET],\n",
        "#     # Optional\n",
        "#     transformation_config=rag.TransformationConfig(\n",
        "#         chunking_config=rag.ChunkingConfig(chunk_size=1024, chunk_overlap=100)\n",
        "#     ),\n",
        "#     max_embedding_requests_per_min=900,  # Optional\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a84095746d"
      },
      "source": [
        "### Import files from Google Drive\n",
        "\n",
        "Eligible paths can be formatted as:\n",
        "\n",
        "- `https://drive.google.com/drive/folders/{folder_id}`\n",
        "- `https://drive.google.com/file/d/{file_id}`.\n",
        "\n",
        "Remember to grant \"Viewer\" access to the \"Vertex RAG Data Service Agent\" (with the format of `service-{project_number}@gcp-sa-vertex-rag.iam.gserviceaccount.com`) for your Drive folder/files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a90c125874c"
      },
      "outputs": [],
      "source": [
        "# response = rag.import_files(\n",
        "#     corpus_name=rag_corpus.name,\n",
        "#     paths=[\"https://drive.google.com/drive/folders/{folder_id}\"],\n",
        "#     # Optional\n",
        "#     transformation_config=rag.TransformationConfig(\n",
        "#         chunking_config=rag.ChunkingConfig(chunk_size=512, chunk_overlap=50)\n",
        "#     ),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f700b3e23121"
      },
      "source": [
        "### Optional: Perform direct context retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4669c5cdbb5a"
      },
      "outputs": [],
      "source": [
        "# Direct context retrieval\n",
        "response = rag.retrieval_query(\n",
        "    rag_resources=[\n",
        "        rag.RagResource(\n",
        "            rag_corpus=rag_corpus.name,\n",
        "            # Optional: supply IDs from `rag.list_files()`.\n",
        "            # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
        "        )\n",
        "    ],\n",
        "    rag_retrieval_config=rag.RagRetrievalConfig(\n",
        "        top_k=10,  # Optional\n",
        "        filter=rag.Filter(\n",
        "            vector_distance_threshold=0.5,  # Optional\n",
        "        ),\n",
        "    ),\n",
        "    text=\"Get me a summary of this health report?\",\n",
        ")\n",
        "print(response)\n",
        "\n",
        "# Optional: The retrieved context can be passed to any SDK or model generation API to generate final results.\n",
        "# context = \" \".join([context.text for context in response.contexts.contexts]).replace(\"\\n\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ea89661842"
      },
      "source": [
        "### Create RAG Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0ebceac3d816"
      },
      "outputs": [],
      "source": [
        "# Create a tool for the RAG Corpus\n",
        "rag_retrieval_tool = Tool(\n",
        "    retrieval=Retrieval(\n",
        "        vertex_rag_store=VertexRagStore(\n",
        "            rag_corpora=[rag_corpus.name],\n",
        "            similarity_top_k=10,\n",
        "            vector_distance_threshold=0.5,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d88fa7ede853"
      },
      "source": [
        "### Generate Content with Gemini using RAG Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dd928baecd4"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "124b36be8d5b"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Whats my BMI looks like??\",\n",
        "    config=GenerateContentConfig(tools=[rag_retrieval_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}